{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames_labels(data_path):\n",
    "    \n",
    "    # Initialize the output lists\n",
    "    filenames = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over the 6 different classes\n",
    "    for i in range(6):\n",
    "        class_dir = str(i) + '_signs'\n",
    "        \n",
    "        # Get all the filenames of the dir\n",
    "        filenames_class = os.listdir(os.path.join(data_path, class_dir))\n",
    "        filenames_class = [os.path.join(data_path, class_dir, f) for f in filenames_class if f.endswith('jpg')]\n",
    "        # Add the labels of the corresponding class\n",
    "        labels_class = [i] * len(filenames_class)\n",
    "        labels = labels + labels_class\n",
    "        filenames = filenames + filenames_class\n",
    "        \n",
    "    # Shuffle the filenames and labels randomly\n",
    "    z = list(zip(filenames, labels))\n",
    "    random.shuffle(z)\n",
    "    filenames, labels = zip(*z)\n",
    "    \n",
    "    out = {'filenames': filenames, 'labels':labels}\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_inputs = get_filenames_labels('data/SIGNS_processed/train_signs/')\n",
    "dev_raw_inputs = get_filenames_labels('data/SIGNS_processed/dev_signs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_int64(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def wrap_bytes(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to_TFRecord(image_paths, labels, out_path, size=(64,64)):\n",
    "    # Args:\n",
    "    # image_paths   List of file-paths for the images.\n",
    "    # labels        Class-labels for the images.\n",
    "    # out_path      File-path for the TFRecords output file.    \n",
    "    print(\"Converting: \" + out_path)\n",
    "    \n",
    "    # Number of images. Used when printing the progress.\n",
    "    num_images = len(image_paths)    \n",
    "    \n",
    "    # Open a TFRecordWriter for the output-file.\n",
    "    with tf.python_io.TFRecordWriter(out_path) as writer:        \n",
    "        \n",
    "        # Iterate over all the image-paths and class-labels.\n",
    "        for i, (path, label) in enumerate(zip(image_paths, labels)):\n",
    "            if i % 100 == 0:\n",
    "                print('Progress: {}/{} images converted'.format(i, len(labels)))\n",
    "            # Load the image-file using matplotlib's imread function.\n",
    "            img = Image.open(path)\n",
    "            img = img.resize(size)\n",
    "            img = np.array(img)\n",
    "            # Convert the image to raw bytes.\n",
    "            img_bytes = img.tostring()\n",
    "            # Create a dict with the data we want to save in the\n",
    "            # TFRecords file. You can add more relevant data here.\n",
    "            data = {\n",
    "                'image': wrap_bytes(img_bytes),\n",
    "                'label': wrap_int64(label)\n",
    "            }\n",
    "            # Wrap the data as TensorFlow Features.\n",
    "            feature = tf.train.Features(feature=data)\n",
    "            # Wrap again as a TensorFlow Example.\n",
    "            example = tf.train.Example(features=feature)\n",
    "            # Serialize the data.\n",
    "            serialized = example.SerializeToString()        \n",
    "            # Write the serialized data to the TFRecords file.\n",
    "            writer.write(serialized)\n",
    "            \n",
    "        print('Progress: {}/{} images converted'.format(i+1, len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting: data/SIGNS_TFRecord_v2/train.tfrecords\n",
      "Progress: 0/864 images converted\n",
      "Progress: 100/864 images converted\n",
      "Progress: 200/864 images converted\n",
      "Progress: 300/864 images converted\n",
      "Progress: 400/864 images converted\n",
      "Progress: 500/864 images converted\n",
      "Progress: 600/864 images converted\n",
      "Progress: 700/864 images converted\n",
      "Progress: 800/864 images converted\n",
      "Progress: 864/864 images converted\n",
      "Converting: data/SIGNS_TFRecord_v2/dev.tfrecords\n",
      "Progress: 0/216 images converted\n",
      "Progress: 100/216 images converted\n",
      "Progress: 200/216 images converted\n",
      "Progress: 216/216 images converted\n"
     ]
    }
   ],
   "source": [
    "convert_to_TFRecord(\n",
    "    image_paths=train_raw_inputs['filenames'],\n",
    "    labels=train_raw_inputs['labels'],\n",
    "    out_path='data/SIGNS_TFRecord_v2/train.tfrecords'\n",
    ")\n",
    "\n",
    "convert_to_TFRecord(\n",
    "    image_paths=dev_raw_inputs['filenames'],\n",
    "    labels=dev_raw_inputs['labels'],\n",
    "    out_path='data/SIGNS_TFRecord_v2/dev.tfrecords'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(serialized):\n",
    "    features = \\\n",
    "    {\n",
    "        'image': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'label': tf.FixedLenFeature((), tf.int64, default_value=0)\n",
    "    }\n",
    "    # Parse the serialized data so we get a dict with our data.\n",
    "    parsed_example = tf.parse_single_example(serialized=serialized,\n",
    "                                             features=features)\n",
    "    # Get the image as raw bytes.\n",
    "    image_shape = tf.stack([64, 64, 3])\n",
    "    image_raw = parsed_example['image']\n",
    "    label = tf.cast(parsed_example['label'], tf.int32)\n",
    "    \n",
    "    # Decode the raw bytes so it becomes a tensor with type.\n",
    "    image = tf.decode_raw(image_raw, tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    #image = tf.subtract(image, 116.779) # Zero-center by mean pixel\n",
    "    image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(_parse_function)  # Parse the record into tensors.\n",
    "dataset = dataset.shuffle()\n",
    "dataset = dataset.repeat()  # Repeat the input indefinitely.\n",
    "dataset = dataset.batch(32).prefetch(32)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "# You can feed the initializer with the appropriate filenames for the current\n",
    "# phase of execution, e.g. training vs. validation.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize `iterator` with training data.\n",
    "training_filenames = ['data/SIGNS_TFRecord_v2/train.tfrecords']\n",
    "sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "\n",
    "image, label = sess.run(iterator.get_next())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 64, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 4, 2, 1, 0, 0, 4, 4, 2, 0, 2, 2, 5, 0, 1, 0, 0, 5, 1, 4, 0,\n",
       "       0, 2, 5, 2, 1, 5, 1, 4, 2, 5], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
