{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a set of TFRecords files for training our model'''\n",
    "\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'data/retina_data_subset/'\n",
    "output_dir = 'data/retina_data_subset_preprocessed/'\n",
    "illnesses = ['altpig', 'dmae', 'excavation', 'membrana', 'nevus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in altpig/train/normal: 267\n",
      "Number of files in dmae/train/normal: 1000\n",
      "Number of files in excavation/train/normal: 382\n",
      "Number of files in membrana/train/normal: 246\n",
      "Number of files in nevus/train/normal: 279\n",
      "Number of total directories: 30\n"
     ]
    }
   ],
   "source": [
    "# Count the number of files in each directory and perform a summary in a table\n",
    "count = 0\n",
    "for illness in illnesses:\n",
    "    illness_dir = 'u_{}_symbolic_512'.format(illness)    \n",
    "    for mode in ['test', 'train', 'validation']:    \n",
    "        for class_type in [illness, 'normal']:\n",
    "            count += 1\n",
    "            filenames_dir = os.path.join(input_dir, illness_dir, mode, class_type)\n",
    "            filenames = [f for f in os.listdir(filenames_dir) if f.endswith('jpg')]\n",
    "            \n",
    "            if class_type == 'normal' and mode == 'train':\n",
    "                print('Number of files in {}/{}/{}: {}'.format(illness, mode, class_type, len(filenames)))\n",
    "print('Number of total directories: {}'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Should we need to apply some preprocessing before turning our images into TFRecords, we can create the functions in this section (resize, applying filters...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save(filename, output_dir, output_size):\n",
    "    '''\n",
    "    Given a filename from an image, resize it into (output_size, output_size) and save it into the ouput_dir path\n",
    "    '''\n",
    "    \n",
    "    img = Image.open(filename)\n",
    "    img = img.resize(size=(output_size, output_size), resample=Image.BILINEAR)\n",
    "    img.save(output_dir)\n",
    "    \n",
    "    \n",
    "def resize_images_from_dir(input_parent_dir, illnesses_list, output_parent_dir, output_image_size):\n",
    "    '''\n",
    "    Given a parent directory, get all the images from inside, resize them into (output_image_size, output_image_size)\n",
    "    and save them into a output parent directory with the same structure\n",
    "    '''\n",
    "    \n",
    "    for illness in illnesses_list:\n",
    "        illness_dir = 'u_{}_symbolic_512'.format(illness)    \n",
    "        for mode in ['test', 'train', 'validation']:    \n",
    "            for class_type in [illness, 'normal']:\n",
    "                filenames_dir = os.path.join(input_parent_dir, illness_dir, mode, class_type)\n",
    "                filenames = [f for f in os.listdir(filenames_dir) if f.endswith('jpg')]\n",
    "\n",
    "                print('Processing files located at {}'.format(filenames_dir))\n",
    "                for i, file in enumerate(filenames):\n",
    "                    if i % 500 == 0:\n",
    "                        # Print some feedback information about the process\n",
    "                        print('{}/{} files processed'.format(i, len(filenames)))\n",
    "                    if i == (len(filenames) - 1):\n",
    "                        print('{}/{} files processed'.format(i+1, len(filenames)))\n",
    "\n",
    "                    # Join all the parts of the filenames\n",
    "                    img_path = os.path.join(input_dir, illness_dir, mode, class_type, file)\n",
    "                    output_dir_file = os.path.join(output_parent_dir, illness_dir, mode, class_type, file)\n",
    "                    # Resize the image to the desired shape and save it at the output directory\n",
    "                    resize_and_save(filename=img_path, output_dir=output_dir_file, output_size=output_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the TFRecords file\n",
    "We will have 3 different sets of files: Training, validation and testing. Each file will contain shuffled images of both all the illnesses and the 'normal' group with the corresponding label\n",
    "Each file will contain 200 coded images tops (This number may change, and needs to be a not hardcoded parameter)\n",
    "\n",
    "We will create a preproc_fn() in which we will code a possible preprocessing\n",
    "\n",
    "6 different classes:\n",
    " - normal = 0\n",
    " - altpig = 1\n",
    " - dmae = 2\n",
    " - excavation = 3\n",
    " - membrana = 4\n",
    " - nevus = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_labels_from_illness(illness, n_filenames):\n",
    "    '''\n",
    "    Returns a list with the id of the illness and length of n_filenames\n",
    "    '''\n",
    "    \n",
    "    assert illness in ['normal', 'altpig', 'dmae', 'excavation', 'membrana', 'nevus'], 'The introduced illness does not exist'\n",
    "    assert n_filenames != 0, 'The number of filenames should be greater than 0'\n",
    "    \n",
    "    if illness == 'normal':\n",
    "        illness_id = 0\n",
    "    elif illness == 'altpig':\n",
    "        illness_id = 1\n",
    "    elif illness == 'dmae':\n",
    "        illness_id = 2\n",
    "    elif illness == 'excavation':\n",
    "        illness_id = 3\n",
    "    elif illness == 'membrana':\n",
    "        illness_id = 4\n",
    "    elif illness == 'nevus':\n",
    "        illness_id = 5\n",
    "    else:\n",
    "        raise ValueError('The introduced illness \"{}\" does not exist.'.format(illness))\n",
    "    \n",
    "    return [illness_id]*n_filenames\n",
    "\n",
    "def get_filenames_labels_mode(parent_dir, mode_to_retrieve, shuffle = False):\n",
    "    '''\n",
    "    Given the parent_dir and the mode ('train', 'test', 'validation'), this function returns a dictionary with the names of\n",
    "    all the filenames found inside the parent directory and the corresponding labels\n",
    "    '''\n",
    "    \n",
    "    assert os.path.isdir(parent_dir), 'The parent directory specified does not exist'\n",
    "    assert mode_to_retrieve in ['train', 'test', 'validation'], 'The specified mode does not exist. Options: \"train\", \"test\", \"validation\"'\n",
    "\n",
    "    illness_dirs = glob.glob(parent_dir + '/*') # illness level\n",
    "    filenames = [] # create an empty list for saving the filenames\n",
    "    labels = [] # create an empty list for saving the labels\n",
    "    \n",
    "    for illness_dir in illness_dirs:\n",
    "\n",
    "        mode_dirs = glob.glob(illness_dir + '/*') # mode level\n",
    "        \n",
    "        for mode_dir in mode_dirs:\n",
    "            mode = mode_dir.split('/')[-1] # retrieve the last part of the pathname (the mode)\n",
    "            if mode == mode_to_retrieve:\n",
    "                class_dirs = glob.glob(mode_dir + '/*') # class level\n",
    "                \n",
    "                for class_dir in class_dirs:\n",
    "                    illness = class_dir.split('/')[-1] # get which illness are we processing now\n",
    "                    \n",
    "                    # Retrieve the filenames and corresponding labels\n",
    "                    filenames_to_retrieve = [f for f in glob.glob(class_dir + '/*') if f.endswith('.jpg')]\n",
    "                    labels_to_retrieve = get_labels_from_illness(illness=illness, n_filenames=len(filenames_to_retrieve))\n",
    "                    \n",
    "                    assert len(filenames_to_retrieve) == len(labels_to_retrieve), 'The lengths of the retrieve filenames and labels do not coincide.'\n",
    "                    \n",
    "                    # Append the previous results to the overall lists\n",
    "                    filenames = filenames + filenames_to_retrieve\n",
    "                    labels = labels + labels_to_retrieve\n",
    "\n",
    "    # Check everything is going smooth\n",
    "    assert len(filenames) == len(labels), 'The lengths of the total filenames and labels do not coincide.'\n",
    "    \n",
    "    # Shuffle the lists randomly if specified\n",
    "    if shuffle:\n",
    "        z = list(zip(filenames, labels))\n",
    "        random.shuffle(z)\n",
    "        filenames, labels = zip(*z)   \n",
    "    \n",
    "    out = {'filenames': filenames, 'labels':labels}\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3735\n",
      "Validation size: 884\n",
      "Test size: 1170\n"
     ]
    }
   ],
   "source": [
    "train_inputs = get_filenames_labels_mode(parent_dir='retina_data_subset/', mode_to_retrieve='train', shuffle=True)\n",
    "n_train = len(train_inputs['filenames'])\n",
    "print('Train size: {}'.format(n_train))\n",
    "\n",
    "validation_inputs = get_filenames_labels_mode(parent_dir='retina_data_subset/', mode_to_retrieve='validation', shuffle=True)\n",
    "n_val = len(validation_inputs['filenames'])\n",
    "print('Validation size: {}'.format(n_val))\n",
    "\n",
    "test_inputs = get_filenames_labels_mode(parent_dir='retina_data_subset/', mode_to_retrieve='test', shuffle=True)\n",
    "n_test = len(test_inputs['filenames'])\n",
    "print('Test size: {}'.format(n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the classes\n",
    "train_hist = plt.hist(x=train_inputs['labels'], bins = 6, histtype='bar', rwidth = 0.75)\n",
    "test_hist = plt.hist(x=test_inputs['labels'], bins = 6, histtype='bar', rwidth = 0.75)\n",
    "valiation_hist = plt.hist(x=validation_inputs['labels'], bins = 6, histtype='bar', rwidth = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_int64(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def wrap_bytes(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def convert_list_to_TFRecord(image_paths, labels, output_name, output_size_files = 200, resize = False, new_size = None):\n",
    "    '''\n",
    "    Args:\n",
    "    image_paths           List of file-paths for the images.\n",
    "    labels                Class-labels for the images.\n",
    "    output_name           File-name for the TFRecords output file, without the extension (.tfrecords)   \n",
    "    output_size_files     Number of images saved in each .tfrecords file\n",
    "    resize                Boolean indicating whether we want the images resized before saving them into TFRecords\n",
    "    new_size              Integer indicating the new size of the images. Deprecated if resize = False\n",
    "    '''\n",
    "    \n",
    "    assert len(image_paths) == len(labels), 'Number of image paths and labels do not coincide.'\n",
    "    \n",
    "    # Compute the number of needed TFRecords files\n",
    "    n_files_created = 0\n",
    "    n_files_needed = len(image_paths)//output_size_files + 1\n",
    "    n_written_images = 0\n",
    "    \n",
    "    # Iterate over the diferent TFRecords files that will be created\n",
    "    for file_id in range(n_files_needed):\n",
    "        output_file_name = output_name + '_' + str(file_id) + '.tfrecords'\n",
    "        print(\"Creating new file: {}\".format(output_file_name))\n",
    "        n_files_created += 1\n",
    "        \n",
    "        # Retrieve the next batch of size 'output_size_files' of filenames and labels\n",
    "        initial_image_id = file_id * output_size_files\n",
    "        final_image_id = (file_id + 1) * output_size_files\n",
    "        image_paths_to_be_coded = image_paths[initial_image_id:final_image_id]\n",
    "        labels_to_be_coded = labels[initial_image_id:final_image_id]\n",
    "        \n",
    "        # Bug-free code\n",
    "        assert len(image_paths_to_be_coded) == len(labels_to_be_coded), 'The next batch of filenames, labels has a mismatch of lenghts'\n",
    "        \n",
    "        # Open a new TFRecordWriter to write the filenames and labels into a TFRecords file\n",
    "        with tf.python_io.TFRecordWriter(output_file_name) as writer:\n",
    "        \n",
    "            # Iterate over all the image-paths and class-labels.\n",
    "            for i, (path, label) in enumerate(zip(image_paths_to_be_coded, labels_to_be_coded)):\n",
    "\n",
    "                # Load the image-file using matplotlib's imread function.\n",
    "                img = Image.open(path)\n",
    "                # Resize the image to the desired size\n",
    "                if resize:\n",
    "                    img = img.resize(size=size, resample=Image.BILINEAR)\n",
    "                # Transform the image into a numpy array and get the features to save\n",
    "                img = np.asarray(img, dtype=np.float32)\n",
    "                rows, cols, depth = img.shape[0], img.shape[1], img.shape[2]\n",
    "                # Convert the image to raw bytes.\n",
    "                img_bytes = tf.compat.as_bytes(img.tostring())\n",
    "                # Create a dict with the data we want to save in the\n",
    "                # TFRecords file. You can add more relevant data here.\n",
    "                data = {\n",
    "                    'image': wrap_bytes(img_bytes),\n",
    "                    'label': wrap_int64(label),\n",
    "                    'height': wrap_int64(rows),\n",
    "                    'width': wrap_int64(cols),\n",
    "                    'depth': wrap_int64(depth),\n",
    "                }\n",
    "                # Wrap the data as TensorFlow Features.\n",
    "                feature = tf.train.Features(feature=data)\n",
    "                # Wrap again as a TensorFlow Example.\n",
    "                example = tf.train.Example(features=feature)\n",
    "                # Serialize the data.\n",
    "                serialized = example.SerializeToString()\n",
    "                # Write the serialized data to the TFRecords file.\n",
    "                writer.write(serialized)\n",
    "                # Update the number of written images for printing the process\n",
    "                n_written_images += 1\n",
    "                \n",
    "        # Print the progress at the end of every file and flush the memory\n",
    "        print('Progress: {}/{} images converted'.format(n_written_images, len(labels)))\n",
    "        # Check that the created file has the expected amount of files\n",
    "        len_tfrecord = len([x for x in tf.python_io.tf_record_iterator(output_file_name)])\n",
    "        assert len_tfrecord == len(image_paths_to_be_coded), 'Expected size of the TFRecord file does not coincide with the input size of the list of filenames'\n",
    "        # Flush the memory\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Creating train files\n",
      "Creating new file: retina_TFRecords/train/train_0.tfrecords\n",
      "Progress: 200/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_1.tfrecords\n",
      "Progress: 400/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_2.tfrecords\n",
      "Progress: 600/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_3.tfrecords\n",
      "Progress: 800/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_4.tfrecords\n",
      "Progress: 1000/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_5.tfrecords\n",
      "Progress: 1200/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_6.tfrecords\n",
      "Progress: 1400/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_7.tfrecords\n",
      "Progress: 1600/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_8.tfrecords\n",
      "Progress: 1800/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_9.tfrecords\n",
      "Progress: 2000/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_10.tfrecords\n",
      "Progress: 2200/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_11.tfrecords\n",
      "Progress: 2400/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_12.tfrecords\n",
      "Progress: 2600/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_13.tfrecords\n",
      "Progress: 2800/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_14.tfrecords\n",
      "Progress: 3000/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_15.tfrecords\n",
      "Progress: 3200/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_16.tfrecords\n",
      "Progress: 3400/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_17.tfrecords\n",
      "Progress: 3600/3735 images converted\n",
      "Creating new file: retina_TFRecords/train/train_18.tfrecords\n",
      "Progress: 3735/3735 images converted\n",
      "Progress: 3735/3735 images converted\n",
      "----- Creating validation files\n",
      "Creating new file: retina_TFRecords/validation/validation_0.tfrecords\n",
      "Progress: 200/884 images converted\n",
      "Creating new file: retina_TFRecords/validation/validation_1.tfrecords\n",
      "Progress: 400/884 images converted\n",
      "Creating new file: retina_TFRecords/validation/validation_2.tfrecords\n",
      "Progress: 600/884 images converted\n",
      "Creating new file: retina_TFRecords/validation/validation_3.tfrecords\n",
      "Progress: 800/884 images converted\n",
      "Creating new file: retina_TFRecords/validation/validation_4.tfrecords\n",
      "Progress: 884/884 images converted\n",
      "Progress: 884/884 images converted\n",
      "----- Creating test files\n",
      "Creating new file: retina_TFRecords/test/test_0.tfrecords\n",
      "Progress: 200/1170 images converted\n",
      "Creating new file: retina_TFRecords/test/test_1.tfrecords\n",
      "Progress: 400/1170 images converted\n",
      "Creating new file: retina_TFRecords/test/test_2.tfrecords\n",
      "Progress: 600/1170 images converted\n",
      "Creating new file: retina_TFRecords/test/test_3.tfrecords\n",
      "Progress: 800/1170 images converted\n",
      "Creating new file: retina_TFRecords/test/test_4.tfrecords\n",
      "Progress: 1000/1170 images converted\n",
      "Creating new file: retina_TFRecords/test/test_5.tfrecords\n",
      "Progress: 1170/1170 images converted\n",
      "Progress: 1170/1170 images converted\n",
      "TFRecord converter process finished.\n"
     ]
    }
   ],
   "source": [
    "train_inputs = get_filenames_labels_mode(parent_dir='retina_data_subset/',\n",
    "                                              mode_to_retrieve='train', shuffle=True)\n",
    "validation_inputs = get_filenames_labels_mode(parent_dir='retina_data_subset/',\n",
    "                                              mode_to_retrieve='validation', shuffle=True)\n",
    "test_inputs = get_filenames_labels_mode(parent_dir='retina_data_subset/',\n",
    "                                              mode_to_retrieve='test', shuffle=True)\n",
    "\n",
    "print('----- Creating train files')\n",
    "convert_list_to_TFRecord(\n",
    "    image_paths=train_inputs['filenames'],\n",
    "    labels=train_inputs['labels'],\n",
    "    output_name = ('retina_TFRecords/train/train'),\n",
    "    output_size_files = 200,\n",
    "    resize = False\n",
    ")\n",
    "\n",
    "print('----- Creating validation files')\n",
    "convert_list_to_TFRecord(\n",
    "    image_paths=validation_inputs['filenames'],\n",
    "    labels=validation_inputs['labels'],\n",
    "    output_name = ('retina_TFRecords/validation/validation'),\n",
    "    output_size_files = 200,\n",
    "    resize = False\n",
    ")\n",
    "\n",
    "print('----- Creating test files')\n",
    "convert_list_to_TFRecord(\n",
    "    image_paths=test_inputs['filenames'],\n",
    "    labels=test_inputs['labels'],\n",
    "    output_name = ('retina_TFRecords/test/test'),\n",
    "    output_size_files = 200,\n",
    "    resize = False\n",
    ")\n",
    "\n",
    "print('TFRecord converter process finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
