{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a set of TFRecords files for training our model'''\n",
    "\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the TFRecords file\n",
    "We will have 6*3 = 9 different sets of files: Training, validation and testing for each pathology. Each file will contain images of one class of pathology and the corresponding label.\n",
    "\n",
    "We will create a preproc_fn() in which we will code a possible preprocessing\n",
    "\n",
    "6 different classes:\n",
    " - normal = 0\n",
    " - altpig = 1\n",
    " - dmae = 2\n",
    " - excavation = 3\n",
    " - membrana = 4\n",
    " - nevus = 5\n",
    "\n",
    "We will create one TFRecord file for each pathology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_illness(illness, n_filenames):\n",
    "    '''\n",
    "    Returns a list with the id of the illness and length of n_filenames\n",
    "    '''\n",
    "    \n",
    "    assert illness in ['normal', 'altpig', 'dmae', 'excavation', 'membrana', 'nevus'], 'The introduced illness does not exist'\n",
    "    assert n_filenames != 0, 'The number of filenames should be greater than 0'\n",
    "    \n",
    "    if illness == 'normal':\n",
    "        illness_id = 0\n",
    "    elif illness == 'altpig':\n",
    "        illness_id = 1\n",
    "    elif illness == 'dmae':\n",
    "        illness_id = 2\n",
    "    elif illness == 'excavation':\n",
    "        illness_id = 3\n",
    "    elif illness == 'membrana':\n",
    "        illness_id = 4\n",
    "    elif illness == 'nevus':\n",
    "        illness_id = 5\n",
    "    else:\n",
    "        raise ValueError('The introduced illness \"{}\" does not exist.'.format(illness))\n",
    "    \n",
    "    return [illness_id]*n_filenames\n",
    "\n",
    "def get_filenames_labels_mode_pathologies(parent_dir, mode_to_retrieve, class_type_to_retrieve):\n",
    "    '''\n",
    "    Given the parent_dir, the mode ('train', 'test', 'validation') and the class label in string format, this function returns a dictionary with the names of\n",
    "    all the filenames found inside the parent directory with that mode and class label\n",
    "    '''\n",
    "    \n",
    "    assert os.path.isdir(parent_dir), 'The parent directory specified does not exist'\n",
    "    assert mode_to_retrieve in ['train', 'test', 'validation'], 'The specified mode does not exist. Options: \"train\", \"test\", \"validation\"'\n",
    "    assert class_type_to_retrieve in ['altpig', 'dmae', 'excavation', 'membrana', 'nevus']\n",
    "    \n",
    "    # Define the pathology dirname\n",
    "    illness_dir = 'u_{}_symbolic_512'.format(class_type_to_retrieve)\n",
    "    dir_to_search = os.path.join(parent_dir, illness_dir, mode_to_retrieve, class_type_to_retrieve)\n",
    "    # Example: dir_to_search = 'data/retina_data_susbset/u_altpig_symbolic_512/train/altpig'\n",
    "\n",
    "    # Retrieve the filenames and corresponding labels\n",
    "    filenames_to_retrieve = [f for f in glob.glob(dir_to_search + '/*') if f.endswith('.jpg')]\n",
    "    labels_to_retrieve = get_labels_from_illness(illness=class_type_to_retrieve, n_filenames=len(filenames_to_retrieve))\n",
    "\n",
    "    assert len(filenames_to_retrieve) == len(labels_to_retrieve), 'The lengths of the retrieved filenames and labels do not coincide.'\n",
    "    \n",
    "    # Give some feedback\n",
    "    print('Retrieved {} images with label \"{}\"'.format(len(filenames_to_retrieve), class_type_to_retrieve))\n",
    "\n",
    "    out = {'filenames': filenames_to_retrieve, 'labels':labels_to_retrieve}\n",
    "    \n",
    "    return out\n",
    "\n",
    "def get_filenames_labels_mode_healthy(parent_dir, mode_to_retrieve):\n",
    "    '''\n",
    "    Given the parent_dir, the mode ('train', 'test', 'validation'), this function returns a dictionary with the \n",
    "    filenames of 'normal' class found inside the parent directory with that mode.\n",
    "    '''\n",
    "    \n",
    "    assert os.path.isdir(parent_dir), 'The parent directory specified does not exist'\n",
    "    assert mode_to_retrieve in ['train', 'test', 'validation'], 'The specified mode does not exist. Options: \"train\", \"test\", \"validation\"'\n",
    "\n",
    "    filenames = [] # create an empty list for saving the filenames\n",
    "    labels = [] # create an empty list for saving the labels\n",
    "    pathologies = ['altpig', 'dmae', 'excavation', 'membrana', 'nevus']\n",
    "    pathologies_dirs = [os.path.join(parent_dir, 'u_{}_symbolic_512'.format(p)) for p in pathologies]\n",
    "    \n",
    "    for pathology_dir in pathologies_dirs:\n",
    "        mode_dirs = glob.glob(pathology_dir + '/*') # mode level\n",
    "        \n",
    "        for mode_dir in mode_dirs:\n",
    "            mode = mode_dir.split('/')[-1] # retrieve the last part of the pathname (the mode)\n",
    "            if mode == mode_to_retrieve:\n",
    "                dir_to_search = mode_dir + '/normal/*' # We only want the 'normal' images in this function\n",
    "                \n",
    "                # Retrieve the filenames and corresponding labels\n",
    "                filenames_to_retrieve = [f for f in glob.glob(dir_to_search) if f.endswith('.jpg')]\n",
    "                labels_to_retrieve = get_labels_from_illness(illness='normal', n_filenames=len(filenames_to_retrieve))\n",
    "\n",
    "                assert len(filenames_to_retrieve) == len(labels_to_retrieve), 'The lengths of the retrieve filenames and labels do not coincide.'\n",
    "\n",
    "                # Append the previous results to the overall lists\n",
    "                filenames = filenames + filenames_to_retrieve\n",
    "                labels = labels + labels_to_retrieve\n",
    "\n",
    "    # Check everything is going smooth\n",
    "    assert len(filenames) == len(labels), 'The lengths of the total filenames and labels do not coincide.'\n",
    "    \n",
    "    # Give some feedback\n",
    "    print('Retrieved {} images with label \"normal\"'.format(len(filenames)))\n",
    "    out = {'filenames': filenames, 'labels':labels}\n",
    "    \n",
    "    return out\n",
    "\n",
    "def get_filenames_labels(parent_dir):\n",
    "    \n",
    "    print('\\n ---- Retreving TRAIN filenames ---- \\n')\n",
    "    train = {}\n",
    "    train['normal'] = get_filenames_labels_mode_healthy(parent_dir=parent_dir, mode_to_retrieve='train')\n",
    "    for pathology in pathologies:\n",
    "        train[pathology] = get_filenames_labels_mode_pathologies(parent_dir=parent_dir, mode_to_retrieve='train', \n",
    "                                              class_type_to_retrieve=pathology)\n",
    "    print('\\n ---- Retreving TEST filenames ---- \\n')\n",
    "    test = {}\n",
    "    test['normal'] = get_filenames_labels_mode_healthy(parent_dir=parent_dir, mode_to_retrieve='test')\n",
    "    for pathology in pathologies:\n",
    "        test[pathology] = get_filenames_labels_mode_pathologies(parent_dir=parent_dir, mode_to_retrieve='test', \n",
    "                                              class_type_to_retrieve=pathology)\n",
    "    print('\\n ---- Retreving VALIDATION filenames ---- \\n')\n",
    "    validation = {}\n",
    "    validation['normal'] = get_filenames_labels_mode_healthy(parent_dir=parent_dir, mode_to_retrieve='validation')\n",
    "    for pathology in pathologies:\n",
    "        validation[pathology] = get_filenames_labels_mode_pathologies(parent_dir=parent_dir, mode_to_retrieve='validation', \n",
    "                                              class_type_to_retrieve=pathology)\n",
    "        \n",
    "    return train, test, validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_int64(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def wrap_bytes(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def convert_list_to_TFRecord(image_paths, labels, output_dir, output_name, max_size = 0, resize=False, new_size=None):\n",
    "    '''\n",
    "    Args:\n",
    "    image_paths           List of file-paths for the images.\n",
    "    labels                Class-labels for the images.\n",
    "    output_name           File-name for the TFRecords output file, without the extension (.tfrecords)\n",
    "    max_size              Maximum number of images to be placed in the created file. Unlimited if max_size = 0. \n",
    "                          If max_size is exceeded, more than one file will be created.\n",
    "    output_size_files     Number of images saved in each .tfrecords file\n",
    "    resize                Boolean indicating whether we want the images resized before saving them into TFRecords\n",
    "    new_size              Integer indicating the new size of the images. Deprecated if resize = False\n",
    "    '''\n",
    "\n",
    "    assert len(image_paths) == len(labels), 'Number of image paths and labels do not coincide.'\n",
    "    assert isinstance(max_size, int), 'Parameter max_size must be an integer'\n",
    "    assert max_size >= 0, 'Parameter max_size must be equal or greater than 0'\n",
    "    \n",
    "    if max_size != 0:\n",
    "        # Check wheter the list of image_path is greater than max_size\n",
    "        if len(image_paths) > max_size:\n",
    "            n_files_to_be_created = (len(image_paths) // max_size) + 1\n",
    "            print('WARNING: Max_size is exceeded. {} files will be created with maximum size {} to place the {} images and labels'.format(n_files_to_be_created, max_size, len(image_paths)))\n",
    "        else:\n",
    "            n_files_to_be_created = 1\n",
    "    elif max_size == 0:\n",
    "        n_files_to_be_created = 1\n",
    "            \n",
    "    # Create the name of the file/s that will be created\n",
    "    filenames_to_be_created = [output_name + str(f) + '.tfrecords' for f in range(n_files_to_be_created)]\n",
    "            \n",
    "    for file_id, filename_to_be_created in enumerate(filenames_to_be_created):\n",
    "        print('----- Creating {} file -----'.format(filename_to_be_created))\n",
    "        # Output file path\n",
    "        output_path = os.path.join(output_dir, filename_to_be_created)\n",
    "        \n",
    "        # Choose which filenames and labels need to be placed in this file\n",
    "        if n_files_to_be_created > 1:\n",
    "            initial_idx = max_size * file_id\n",
    "            final_idx = max_size * (file_id + 1)\n",
    "            image_paths_batch = image_paths[initial_idx:final_idx]\n",
    "            labels_batch = labels[initial_idx:final_idx]\n",
    "\n",
    "        else:\n",
    "            image_paths_batch = image_paths\n",
    "            labels_batch = labels\n",
    "\n",
    "        # Open a new TFRecordWriter to write the filenames and labels into a TFRecords file\n",
    "        with tf.python_io.TFRecordWriter(output_path) as writer:\n",
    "            # Iterate over all the image-paths and class-labels.\n",
    "            for i, (path, label) in enumerate(zip(image_paths_batch, labels_batch)):\n",
    "\n",
    "                # Print the progress\n",
    "                if i % 200 == 0:\n",
    "                    print('Progress: {}/{} images converted'.format(i, len(labels_batch)))\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                # Load the image-file using matplotlib's imread function.\n",
    "                img = Image.open(path)\n",
    "                # Optional: Resize the image to the desired size\n",
    "                if resize:\n",
    "                    img = img.resize(size=new_size, resample=Image.BILINEAR)\n",
    "\n",
    "                # Transform the image into a numpy array and get the features to save\n",
    "                img = np.asarray(img, dtype=np.float32)\n",
    "                rows, cols, depth = img.shape[0], img.shape[1], img.shape[2]\n",
    "                # Convert the image to raw bytes.\n",
    "                img_bytes = tf.compat.as_bytes(img.tostring())\n",
    "                # Create a dict with the data we want to save in the\n",
    "                # TFRecords file. You can add more relevant data here.\n",
    "                data = {\n",
    "                    'image': wrap_bytes(img_bytes),\n",
    "                    'label': wrap_int64(label),\n",
    "                    'height': wrap_int64(rows),\n",
    "                    'width': wrap_int64(cols),\n",
    "                    'depth': wrap_int64(depth),\n",
    "                }\n",
    "                # Wrap the data as TensorFlow Features.\n",
    "                feature = tf.train.Features(feature=data)\n",
    "                # Wrap again as a TensorFlow Example.\n",
    "                example = tf.train.Example(features=feature)\n",
    "                # Serialize the data.\n",
    "                serialized = example.SerializeToString()\n",
    "                # Write the serialized data to the TFRecords file.\n",
    "                writer.write(serialized)\n",
    "\n",
    "        # Check that the created file has the expected amount of files\n",
    "        print(output_path)\n",
    "        len_tfrecord = len([x for x in tf.python_io.tf_record_iterator(output_path)])    \n",
    "        assert len_tfrecord == len(image_paths_batch), 'Expected size of the created TFRecord file does not coincide with the input size of the list of filenames'\n",
    "    \n",
    "    # Flush the memory\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def create_TFRecords(train, test, validation, output_dir):\n",
    "    print('\\n ---- Creating TRAIN files in TFRecords format ----')\n",
    "    for pathology in train.keys():\n",
    "        convert_list_to_TFRecord(\n",
    "            image_paths=train[pathology]['filenames'], \n",
    "            labels=train[pathology]['labels'],\n",
    "            output_dir=output_dir,\n",
    "            output_name='train/train_{}'.format(pathology),\n",
    "            max_size = 200)\n",
    "\n",
    "\n",
    "    print('\\n ---- Creating TEST files in TFRecords format ----')\n",
    "    for pathology in test.keys():\n",
    "        convert_list_to_TFRecord(\n",
    "            image_paths=test[pathology]['filenames'], \n",
    "            labels=test[pathology]['labels'],\n",
    "            output_dir=output_dir,\n",
    "            output_name='test/test_{}'.format(pathology))\n",
    "\n",
    "\n",
    "    print('\\n ---- Creating VALIDATION files in TFRecords format ----')\n",
    "    for pathology in validation.keys():\n",
    "        convert_list_to_TFRecord(\n",
    "            image_paths=validation[pathology]['filenames'], \n",
    "            labels=validation[pathology]['labels'],\n",
    "            output_dir=output_dir,\n",
    "            output_name='validation/validation_{}'.format(pathology))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Getting the filenames and labels ####\n",
      "\n",
      "---- Retreving TRAIN filenames ---- \n",
      "\n",
      "Retrieved 2174 images with label \"normal\"\n",
      "Retrieved 94 images with label \"altpig\"\n",
      "Retrieved 922 images with label \"dmae\"\n",
      "Retrieved 187 images with label \"excavation\"\n",
      "Retrieved 183 images with label \"membrana\"\n",
      "Retrieved 175 images with label \"nevus\"\n",
      "---- Retreving TEST filenames ---- \n",
      "\n",
      "Retrieved 679 images with label \"normal\"\n",
      "Retrieved 20 images with label \"altpig\"\n",
      "Retrieved 279 images with label \"dmae\"\n",
      "Retrieved 65 images with label \"excavation\"\n",
      "Retrieved 79 images with label \"membrana\"\n",
      "Retrieved 48 images with label \"nevus\"\n",
      "---- Retreving VALIDATION filenames ---- \n",
      "\n",
      "Retrieved 486 images with label \"normal\"\n",
      "Retrieved 20 images with label \"altpig\"\n",
      "Retrieved 235 images with label \"dmae\"\n",
      "Retrieved 51 images with label \"excavation\"\n",
      "Retrieved 51 images with label \"membrana\"\n",
      "Retrieved 41 images with label \"nevus\"\n",
      "\n",
      "##### Creating the TFRecords files ####\n",
      "\n",
      "---- Creating train files in TFRecords format ----\n",
      "WARNING: Max_size is exceeded. 11 files will be created with maximum size 200 to place the 2174 images and labels\n",
      "----- Creating train/train_normal0.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal0.tfrecords\n",
      "----- Creating train/train_normal1.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal1.tfrecords\n",
      "----- Creating train/train_normal2.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal2.tfrecords\n",
      "----- Creating train/train_normal3.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal3.tfrecords\n",
      "----- Creating train/train_normal4.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal4.tfrecords\n",
      "----- Creating train/train_normal5.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal5.tfrecords\n",
      "----- Creating train/train_normal6.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal6.tfrecords\n",
      "----- Creating train/train_normal7.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal7.tfrecords\n",
      "----- Creating train/train_normal8.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal8.tfrecords\n",
      "----- Creating train/train_normal9.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_normal9.tfrecords\n",
      "----- Creating train/train_normal10.tfrecords file -----\n",
      "Progress: 0/174 images converted\n",
      "data/retina_TFRecords/train/train_normal10.tfrecords\n",
      "----- Creating train/train_altpig0.tfrecords file -----\n",
      "Progress: 0/94 images converted\n",
      "data/retina_TFRecords/train/train_altpig0.tfrecords\n",
      "WARNING: Max_size is exceeded. 5 files will be created with maximum size 200 to place the 922 images and labels\n",
      "----- Creating train/train_dmae0.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_dmae0.tfrecords\n",
      "----- Creating train/train_dmae1.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_dmae1.tfrecords\n",
      "----- Creating train/train_dmae2.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_dmae2.tfrecords\n",
      "----- Creating train/train_dmae3.tfrecords file -----\n",
      "Progress: 0/200 images converted\n",
      "data/retina_TFRecords/train/train_dmae3.tfrecords\n",
      "----- Creating train/train_dmae4.tfrecords file -----\n",
      "Progress: 0/122 images converted\n",
      "data/retina_TFRecords/train/train_dmae4.tfrecords\n",
      "----- Creating train/train_excavation0.tfrecords file -----\n",
      "Progress: 0/187 images converted\n",
      "data/retina_TFRecords/train/train_excavation0.tfrecords\n",
      "----- Creating train/train_membrana0.tfrecords file -----\n",
      "Progress: 0/183 images converted\n",
      "data/retina_TFRecords/train/train_membrana0.tfrecords\n",
      "----- Creating train/train_nevus0.tfrecords file -----\n",
      "Progress: 0/175 images converted\n",
      "data/retina_TFRecords/train/train_nevus0.tfrecords\n",
      "---- Creating test files in TFRecords format ----\n",
      "----- Creating test/test_normal0.tfrecords file -----\n",
      "Progress: 0/679 images converted\n",
      "Progress: 200/679 images converted\n",
      "Progress: 400/679 images converted\n",
      "Progress: 600/679 images converted\n",
      "data/retina_TFRecords/test/test_normal0.tfrecords\n",
      "----- Creating test/test_altpig0.tfrecords file -----\n",
      "Progress: 0/20 images converted\n",
      "data/retina_TFRecords/test/test_altpig0.tfrecords\n",
      "----- Creating test/test_dmae0.tfrecords file -----\n",
      "Progress: 0/279 images converted\n",
      "Progress: 200/279 images converted\n",
      "data/retina_TFRecords/test/test_dmae0.tfrecords\n",
      "----- Creating test/test_excavation0.tfrecords file -----\n",
      "Progress: 0/65 images converted\n",
      "data/retina_TFRecords/test/test_excavation0.tfrecords\n",
      "----- Creating test/test_membrana0.tfrecords file -----\n",
      "Progress: 0/79 images converted\n",
      "data/retina_TFRecords/test/test_membrana0.tfrecords\n",
      "----- Creating test/test_nevus0.tfrecords file -----\n",
      "Progress: 0/48 images converted\n",
      "data/retina_TFRecords/test/test_nevus0.tfrecords\n",
      "---- Creating validation files in TFRecords format ----\n",
      "----- Creating validation/validation_normal0.tfrecords file -----\n",
      "Progress: 0/486 images converted\n",
      "Progress: 200/486 images converted\n",
      "Progress: 400/486 images converted\n",
      "data/retina_TFRecords/validation/validation_normal0.tfrecords\n",
      "----- Creating validation/validation_altpig0.tfrecords file -----\n",
      "Progress: 0/20 images converted\n",
      "data/retina_TFRecords/validation/validation_altpig0.tfrecords\n",
      "----- Creating validation/validation_dmae0.tfrecords file -----\n",
      "Progress: 0/235 images converted\n",
      "Progress: 200/235 images converted\n",
      "data/retina_TFRecords/validation/validation_dmae0.tfrecords\n",
      "----- Creating validation/validation_excavation0.tfrecords file -----\n",
      "Progress: 0/51 images converted\n",
      "data/retina_TFRecords/validation/validation_excavation0.tfrecords\n",
      "----- Creating validation/validation_membrana0.tfrecords file -----\n",
      "Progress: 0/51 images converted\n",
      "data/retina_TFRecords/validation/validation_membrana0.tfrecords\n",
      "----- Creating validation/validation_nevus0.tfrecords file -----\n",
      "Progress: 0/41 images converted\n",
      "data/retina_TFRecords/validation/validation_nevus0.tfrecords\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "input_dir = 'data/retina_data_subset/'\n",
    "output_dir = 'data/retina_TFRecords/'\n",
    "pathologies = ['altpig', 'dmae', 'excavation', 'membrana', 'nevus']\n",
    "\n",
    "print('##### Getting the filenames and labels ####')\n",
    "print()\n",
    "train, test, validation = get_filenames_labels(parent_dir=input_dir)\n",
    "print()\n",
    "\n",
    "print('##### Creating the TFRecords files ####')\n",
    "print()\n",
    "create_TFRecords(train, test, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
